{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing Functions with MlFlow \n",
    "----------------------------------------------------------------\n",
    "\n",
    "In this notebook, we will explore Snorkel's slicing functions and their use in T2R2 together, paired with mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mlflow\n",
    "start out by running the server locally or elsewhere:\n",
    "\n",
    "```\n",
    "  mlflow server\n",
    "```\n",
    "\n",
    "and set the tracking uri together with the experiment name in the config, the default being:\n",
    "\n",
    "```\n",
    "  experiment_name: 'my_experiment_slicing'\n",
    "  tags:\n",
    "      version: 'v1'\n",
    "  tracking_uri: \"http://localhost:5000\"\n",
    "```\n",
    "\n",
    "after running you can view your experiment in the browser, using the tracking uri.\n",
    "\n",
    "### slicing functions\n",
    "Slicing functions allow you to examine the performance of the model on a variety of defined subsets defined by slicing functions.\n",
    "Specify slicing functions in config. Like this:\n",
    "```\n",
    "  selectors: \n",
    "    - name: slicing\n",
    "      args: \n",
    "        result_file: 'slicing/test_slicing.pickle'\n",
    "        list_of_slicing_functions: [short, textblob_polarity, long]\n",
    "```\n",
    "\n",
    "You can pick them from the avalable list in [default_slicing_functions.py](src\\t2r2\\selector\\slicing\\default_slicing_functions.py) below:\n",
    "\n",
    "```\n",
    "@slicing_function()\n",
    "def short(x):\n",
    "    '''Short texts, below 60 characters'''\n",
    "    return len(x.text.split()) < 60\n",
    "\n",
    "@slicing_function()\n",
    "def long(x):\n",
    "    '''Long texts, above 100 characters'''\n",
    "    return len(x.text.split()) > 100\n",
    "\n",
    "@slicing_function(pre=[textblob_sentiment])\n",
    "def textblob_polarity(x):\n",
    "    '''Slightly more positive sentiment(-1 is negative 1 is positive)'''\n",
    "    return x.polarity > 0.1\n",
    "```\n",
    "\n",
    "But feel free to add your own and contribute to t2r2! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T18:47:29.680742400Z",
     "start_time": "2023-06-06T18:47:26.746571100Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ismyn\\miniconda3\\envs\\enginora_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('C:/Users/ismyn/UNI/t2r2/src')\n",
    "from t2r2 import T2R2\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format=\"[%(filename)s:%(lineno)s - %(funcName)20s() ] %(message)s\", level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T18:47:29.692642500Z",
     "start_time": "2023-06-06T18:47:29.683581900Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['WANDB_DISABLED'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T19:01:32.772699200Z",
     "start_time": "2023-06-06T18:47:29.696640100Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mlflow.py:86 -     set_tracking_uri() ] mlflow: Tracking uri set\n",
      "[mlflow.py:57 - mlflow_create_experiment() ] ***SETTING EXPERIMENT***\n",
      "[mlflow.py:58 - mlflow_create_experiment() ] Name: my_experiment_slicing\n",
      "[mlflow.py:59 - mlflow_create_experiment() ] Experiment_id: 581969234305795169\n",
      "[mlflow.py:60 - mlflow_create_experiment() ] Random State: 123\n",
      "[mlflow.py:61 - mlflow_create_experiment() ] Artifact Location: mlflow-artifacts:/581969234305795169\n",
      "[mlflow.py:62 - mlflow_create_experiment() ] Tags: {'version': 'v1'}\n",
      "[mlflow.py:63 - mlflow_create_experiment() ] Lifecycle_stage: active\n",
      "[mlflow.py:64 - mlflow_create_experiment() ] Creation timestamp: 1701626425478\n",
      "100%|██████████| 12110/12110 [00:10<00:00, 1178.97it/s]\n",
      "100%|██████████| 2585/2585 [00:02<00:00, 1134.60it/s]\n",
      "c:\\Users\\ismyn\\miniconda3\\envs\\enginora_env\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  return _infer_schema(self._df)\n",
      "c:\\Users\\ismyn\\miniconda3\\envs\\enginora_env\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  return _infer_schema(self._df)\n",
      "c:\\Users\\ismyn\\miniconda3\\envs\\enginora_env\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  return _infer_schema(self._df)\n",
      "c:\\Users\\ismyn\\miniconda3\\envs\\enginora_env\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  return _infer_schema(self._df)\n",
      "[mlflow.py:77 -             log_data() ] mlflow: Dataset logged\n",
      "[mlflow.py:94 - log_dataset_synopsis() ] mlflow: Dataset synopsis logged\n",
      "***** Running training *****\n",
      "  Num examples = 100\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 100\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 2\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 2\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 2.5885274410247803, 'train_f1_score': 0.03225806451612903, 'train_slicing_scores_accuracy_overall': 0.24, 'train_slicing_scores_accuracy_short': 0.25862068965517243, 'train_slicing_scores_accuracy_textblob_polarity': 0.22857142857142856, 'train_slicing_scores_accuracy_long': 0.38461538461538464, 'train_runtime': 13.2267, 'train_samples_per_second': 7.56, 'train_steps_per_second': 3.78, 'epoch': 1.0}\n",
      "{'loss': 2.4658, 'learning_rate': 0.0005, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to results/checkpoint-50\n",
      "Configuration saved in results/checkpoint-50\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.040436267852783, 'eval_f1_score': 0.04761904761904762, 'eval_slicing_scores_accuracy_overall': 0.2, 'eval_slicing_scores_accuracy_short': 0.1111111111111111, 'eval_slicing_scores_accuracy_textblob_polarity': 0.3333333333333333, 'eval_slicing_scores_accuracy_long': 0.2, 'eval_runtime': 2.646, 'eval_samples_per_second': 7.558, 'eval_steps_per_second': 3.779, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in results/checkpoint-50\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 2\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 2\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 2.1609227657318115, 'train_f1_score': 0.03543307086614173, 'train_slicing_scores_accuracy_overall': 0.27, 'train_slicing_scores_accuracy_short': 0.29310344827586204, 'train_slicing_scores_accuracy_textblob_polarity': 0.2571428571428571, 'train_slicing_scores_accuracy_long': 0.15384615384615385, 'train_runtime': 13.0576, 'train_samples_per_second': 7.658, 'train_steps_per_second': 3.829, 'epoch': 2.0}\n",
      "{'loss': 2.2813, 'learning_rate': 0.0, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to results/checkpoint-100\n",
      "Configuration saved in results/checkpoint-100\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2329306602478027, 'eval_f1_score': 0.05714285714285715, 'eval_slicing_scores_accuracy_overall': 0.25, 'eval_slicing_scores_accuracy_short': 0.3333333333333333, 'eval_slicing_scores_accuracy_textblob_polarity': 0.1111111111111111, 'eval_slicing_scores_accuracy_long': 0.2, 'eval_runtime': 2.6115, 'eval_samples_per_second': 7.658, 'eval_steps_per_second': 3.829, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in results/checkpoint-100\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-100 (score: 0.05714285714285715).\n",
      "[mlflow.py:68 -          log_metrics() ] mlflow: flattening :train_runtime_train train_samples_per_second_train train_steps_per_second_train train_loss_train epoch_train history_train\n",
      "[mlflow.py:70 -          log_metrics() ] mlflow: logging metrics :train_runtime_train train_samples_per_second_train train_steps_per_second_train train_loss_train epoch_train history_train_0_train_loss history_train_0_train_f1_score history_train_0_train_slicing_scores_accuracy_overall history_train_0_train_slicing_scores_accuracy_short history_train_0_train_slicing_scores_accuracy_textblob_polarity history_train_0_train_slicing_scores_accuracy_long history_train_0_train_runtime history_train_0_train_samples_per_second history_train_0_train_steps_per_second history_train_0_epoch history_train_0_step history_train_1_loss history_train_1_learning_rate history_train_1_epoch history_train_1_step history_train_2_eval_loss history_train_2_eval_f1_score history_train_2_eval_slicing_scores_accuracy_overall history_train_2_eval_slicing_scores_accuracy_short history_train_2_eval_slicing_scores_accuracy_textblob_polarity history_train_2_eval_slicing_scores_accuracy_long history_train_2_eval_runtime history_train_2_eval_samples_per_second history_train_2_eval_steps_per_second history_train_2_epoch history_train_2_step history_train_3_train_loss history_train_3_train_f1_score history_train_3_train_slicing_scores_accuracy_overall history_train_3_train_slicing_scores_accuracy_short history_train_3_train_slicing_scores_accuracy_textblob_polarity history_train_3_train_slicing_scores_accuracy_long history_train_3_train_runtime history_train_3_train_samples_per_second history_train_3_train_steps_per_second history_train_3_epoch history_train_3_step history_train_4_loss history_train_4_learning_rate history_train_4_epoch history_train_4_step history_train_5_eval_loss history_train_5_eval_f1_score history_train_5_eval_slicing_scores_accuracy_overall history_train_5_eval_slicing_scores_accuracy_short history_train_5_eval_slicing_scores_accuracy_textblob_polarity history_train_5_eval_slicing_scores_accuracy_long history_train_5_eval_runtime history_train_5_eval_samples_per_second history_train_5_eval_steps_per_second history_train_5_epoch history_train_5_step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 151.6864, 'train_samples_per_second': 1.319, 'train_steps_per_second': 0.659, 'train_loss': 2.3735517120361327, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to results\\best_model\n",
      "Configuration saved in results\\best_model\\config.json\n",
      "Model weights saved in results\\best_model\\pytorch_model.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 20\n",
      "  Batch size = 2\n",
      "The following columns in the test set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[mlflow.py:68 -          log_metrics() ] mlflow: flattening :test_loss_test test_f1_score_test test_slicing_scores_accuracy_overall_test test_slicing_scores_accuracy_short_test test_slicing_scores_accuracy_textblob_polarity_test test_slicing_scores_accuracy_long_test test_runtime_test test_samples_per_second_test test_steps_per_second_test\n",
      "[mlflow.py:70 -          log_metrics() ] mlflow: logging metrics :test_loss_test test_f1_score_test test_slicing_scores_accuracy_overall_test test_slicing_scores_accuracy_short_test test_slicing_scores_accuracy_textblob_polarity_test test_slicing_scores_accuracy_long_test test_runtime_test test_samples_per_second_test test_steps_per_second_test\n",
      "***** Running Prediction *****\n",
      "  Num examples = 10\n",
      "  Batch size = 2\n",
      "The following columns in the test set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[mlflow.py:68 -          log_metrics() ] mlflow: flattening :control_loss_control control_f1_score_control control_slicing_scores_accuracy_overall_control control_slicing_scores_accuracy_short_control control_slicing_scores_accuracy_textblob_polarity_control control_slicing_scores_accuracy_long_control control_runtime_control control_samples_per_second_control control_steps_per_second_control\n",
      "[mlflow.py:70 -          log_metrics() ] mlflow: logging metrics :control_loss_control control_f1_score_control control_slicing_scores_accuracy_overall_control control_slicing_scores_accuracy_short_control control_slicing_scores_accuracy_textblob_polarity_control control_slicing_scores_accuracy_long_control control_runtime_control control_samples_per_second_control control_steps_per_second_control\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'control_results': {'control_loss': 2.951964855194092,\n",
       "  'control_f1_score': 0.06666666666666668,\n",
       "  'control_slicing_scores_accuracy_overall': 0.2,\n",
       "  'control_slicing_scores_accuracy_short': 0.0,\n",
       "  'control_slicing_scores_accuracy_textblob_polarity': 0.2,\n",
       "  'control_slicing_scores_accuracy_long': 0.3333333333333333,\n",
       "  'control_runtime': 1.3421,\n",
       "  'control_samples_per_second': 7.451,\n",
       "  'control_steps_per_second': 3.725},\n",
       " 'test_results': {'test_loss': 1.8562586307525635,\n",
       "  'test_f1_score': 0.05714285714285715,\n",
       "  'test_slicing_scores_accuracy_overall': 0.25,\n",
       "  'test_slicing_scores_accuracy_short': 0.3333333333333333,\n",
       "  'test_slicing_scores_accuracy_textblob_polarity': 0.1111111111111111,\n",
       "  'test_slicing_scores_accuracy_long': 0.2,\n",
       "  'test_runtime': 2.6719,\n",
       "  'test_samples_per_second': 7.485,\n",
       "  'test_steps_per_second': 3.743},\n",
       " 'train_results': {'train_runtime': 151.6864,\n",
       "  'train_samples_per_second': 1.319,\n",
       "  'train_steps_per_second': 0.659,\n",
       "  'train_loss': 2.3735517120361327,\n",
       "  'epoch': 2.0,\n",
       "  'history': [{'train_loss': 2.5885274410247803,\n",
       "    'train_f1_score': 0.03225806451612903,\n",
       "    'train_slicing_scores_accuracy_overall': 0.24,\n",
       "    'train_slicing_scores_accuracy_short': 0.25862068965517243,\n",
       "    'train_slicing_scores_accuracy_textblob_polarity': 0.22857142857142856,\n",
       "    'train_slicing_scores_accuracy_long': 0.38461538461538464,\n",
       "    'train_runtime': 13.2267,\n",
       "    'train_samples_per_second': 7.56,\n",
       "    'train_steps_per_second': 3.78,\n",
       "    'epoch': 1.0,\n",
       "    'step': 50},\n",
       "   {'loss': 2.4658, 'learning_rate': 0.0005, 'epoch': 1.0, 'step': 50},\n",
       "   {'eval_loss': 3.040436267852783,\n",
       "    'eval_f1_score': 0.04761904761904762,\n",
       "    'eval_slicing_scores_accuracy_overall': 0.2,\n",
       "    'eval_slicing_scores_accuracy_short': 0.1111111111111111,\n",
       "    'eval_slicing_scores_accuracy_textblob_polarity': 0.3333333333333333,\n",
       "    'eval_slicing_scores_accuracy_long': 0.2,\n",
       "    'eval_runtime': 2.646,\n",
       "    'eval_samples_per_second': 7.558,\n",
       "    'eval_steps_per_second': 3.779,\n",
       "    'epoch': 1.0,\n",
       "    'step': 50},\n",
       "   {'train_loss': 2.1609227657318115,\n",
       "    'train_f1_score': 0.03543307086614173,\n",
       "    'train_slicing_scores_accuracy_overall': 0.27,\n",
       "    'train_slicing_scores_accuracy_short': 0.29310344827586204,\n",
       "    'train_slicing_scores_accuracy_textblob_polarity': 0.2571428571428571,\n",
       "    'train_slicing_scores_accuracy_long': 0.15384615384615385,\n",
       "    'train_runtime': 13.0576,\n",
       "    'train_samples_per_second': 7.658,\n",
       "    'train_steps_per_second': 3.829,\n",
       "    'epoch': 2.0,\n",
       "    'step': 100},\n",
       "   {'loss': 2.2813, 'learning_rate': 0.0, 'epoch': 2.0, 'step': 100},\n",
       "   {'eval_loss': 2.2329306602478027,\n",
       "    'eval_f1_score': 0.05714285714285715,\n",
       "    'eval_slicing_scores_accuracy_overall': 0.25,\n",
       "    'eval_slicing_scores_accuracy_short': 0.3333333333333333,\n",
       "    'eval_slicing_scores_accuracy_textblob_polarity': 0.1111111111111111,\n",
       "    'eval_slicing_scores_accuracy_long': 0.2,\n",
       "    'eval_runtime': 2.6115,\n",
       "    'eval_samples_per_second': 7.658,\n",
       "    'eval_steps_per_second': 3.829,\n",
       "    'epoch': 2.0,\n",
       "    'step': 100}]}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttrr = T2R2()\n",
    "ttrr.loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
